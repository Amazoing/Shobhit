{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d77ba23",
   "metadata": {},
   "source": [
    "# Project Overview\n",
    "\n",
    "The project objective is to develop a predictive model that accurately classifies the risk level of life insurance applicants based on a set of attributes provided in the dataset. The \"Response\" variable, which represents the risk level, has 8 ordinal levels. By leveraging machine learning techniques, such as predictive modeling, the goal is to expedite and streamline the insurance application process, thereby increasing the efficiency and accessibility of life insurance services while maintaining privacy boundaries. Ultimately, the successful implementation of the predictive model will not only enhance the customer experience but also improve the public perception of the insurance industry.\n",
    "\n",
    "## Data Preprocessing\n",
    "\n",
    "Data preprocessing steps include concatenation of data, scaling, encoding, and imputation, critical to handling the complexity of the dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "7a6ceb0a",
   "metadata": {
    "id": "216ee00a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing necessary libraries and modules for data preprocessing and modeling\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "14c878b3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "14c878b3",
    "outputId": "a1fd25df-eaf1-4b24-89e1-c28b781d555e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# access the datasets and loading them into pandas DataFrames\n",
    "\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "7f9c99cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = pd.concat([train_data, test_data], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "8eaee816",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = combined_data.drop(columns=['Id', 'Response'])\n",
    "y = combined_data['Response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "136eed5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Assume X contains both continuous and categorical columns\n",
    "# Define your continuous columns\n",
    "continuous_cols = ['Product_Info_4', 'Ins_Age', 'Ht', 'Wt', 'BMI', 'Employment_Info_1', \n",
    "                    'Employment_Info_4', 'Employment_Info_6', 'Insurance_History_5', \n",
    "                    'Family_Hist_2', 'Family_Hist_3', 'Family_Hist_4', 'Family_Hist_5']\n",
    "\n",
    "# Define your categorical columns\n",
    "categorical_cols = ['Product_Info_1', 'Product_Info_2', 'Product_Info_3', 'Product_Info_5', \n",
    "                    'Product_Info_6', 'Product_Info_7', 'Employment_Info_2', 'Employment_Info_3', \n",
    "                    'Employment_Info_5', 'InsuredInfo_1', 'InsuredInfo_2', 'InsuredInfo_3', \n",
    "                    'InsuredInfo_4', 'InsuredInfo_5', 'InsuredInfo_6', 'InsuredInfo_7', \n",
    "                    'Insurance_History_1', 'Insurance_History_2', 'Insurance_History_3', \n",
    "                    'Insurance_History_4', 'Insurance_History_7', 'Insurance_History_8', \n",
    "                    'Insurance_History_9', 'Family_Hist_1', 'Medical_History_2', 'Medical_History_3', \n",
    "                    'Medical_History_4', 'Medical_History_5', 'Medical_History_6', 'Medical_History_7', \n",
    "                    'Medical_History_8', 'Medical_History_9', 'Medical_History_11', 'Medical_History_12', \n",
    "                    'Medical_History_13', 'Medical_History_14', 'Medical_History_16', 'Medical_History_17', \n",
    "                    'Medical_History_18', 'Medical_History_19', 'Medical_History_20', 'Medical_History_21', \n",
    "                    'Medical_History_22', 'Medical_History_23', 'Medical_History_25', 'Medical_History_26', \n",
    "                    'Medical_History_27', 'Medical_History_28', 'Medical_History_29', 'Medical_History_30', \n",
    "                    'Medical_History_31', 'Medical_History_33', 'Medical_History_34', 'Medical_History_35', \n",
    "                    'Medical_History_36', 'Medical_History_37', 'Medical_History_38', 'Medical_History_39', \n",
    "                    'Medical_History_40', 'Medical_History_41']\n",
    "\n",
    "# Assume X contains both continuous and categorical columns\n",
    "# Scale the continuous columns\n",
    "scaler = StandardScaler()\n",
    "X[continuous_cols] = scaler.fit_transform(X[continuous_cols])\n",
    "\n",
    "# One-hot encode the categorical columns\n",
    "encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "X_encoded = encoder.fit_transform(X[categorical_cols])\n",
    "encoded_feature_names = encoder.get_feature_names_out(categorical_cols)\n",
    "X_encoded_df = pd.DataFrame(X_encoded, columns=encoded_feature_names)\n",
    "\n",
    "# Reset the index of X_encoded_df\n",
    "X_encoded_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Drop the categorical columns from X\n",
    "X.drop(columns=categorical_cols, inplace=True)\n",
    "\n",
    "# Reset the index of X\n",
    "X.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Concatenate X with X_encoded_df\n",
    "X = pd.concat([X, X_encoded_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "2417bc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "db4f7da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.fillna(X_train.median())\n",
    "test_data=test_data.fillna(X_test.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "cf49a36f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product_Info_4</th>\n",
       "      <th>Ins_Age</th>\n",
       "      <th>Ht</th>\n",
       "      <th>Wt</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Employment_Info_1</th>\n",
       "      <th>Employment_Info_4</th>\n",
       "      <th>Employment_Info_6</th>\n",
       "      <th>Insurance_History_5</th>\n",
       "      <th>Family_Hist_2</th>\n",
       "      <th>...</th>\n",
       "      <th>Medical_History_38_2</th>\n",
       "      <th>Medical_History_39_1</th>\n",
       "      <th>Medical_History_39_2</th>\n",
       "      <th>Medical_History_39_3</th>\n",
       "      <th>Medical_History_40_1</th>\n",
       "      <th>Medical_History_40_2</th>\n",
       "      <th>Medical_History_40_3</th>\n",
       "      <th>Medical_History_41_1</th>\n",
       "      <th>Medical_History_41_2</th>\n",
       "      <th>Medical_History_41_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.891949</td>\n",
       "      <td>1.803488</td>\n",
       "      <td>0.514174</td>\n",
       "      <td>0.003371</td>\n",
       "      <td>-0.277392</td>\n",
       "      <td>-0.393833</td>\n",
       "      <td>2.559719</td>\n",
       "      <td>-0.405924</td>\n",
       "      <td>1.156639</td>\n",
       "      <td>-0.858012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.891949</td>\n",
       "      <td>-0.467237</td>\n",
       "      <td>-0.955296</td>\n",
       "      <td>-1.288935</td>\n",
       "      <td>-1.111675</td>\n",
       "      <td>-0.454442</td>\n",
       "      <td>-0.410119</td>\n",
       "      <td>-0.626160</td>\n",
       "      <td>1.156639</td>\n",
       "      <td>1.268046</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.559979</td>\n",
       "      <td>-0.997073</td>\n",
       "      <td>0.514174</td>\n",
       "      <td>3.010921</td>\n",
       "      <td>3.273777</td>\n",
       "      <td>-0.212005</td>\n",
       "      <td>-0.410119</td>\n",
       "      <td>-1.214050</td>\n",
       "      <td>1.156639</td>\n",
       "      <td>0.938644</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.347476</td>\n",
       "      <td>0.289671</td>\n",
       "      <td>0.024351</td>\n",
       "      <td>-1.288935</td>\n",
       "      <td>-1.592976</td>\n",
       "      <td>-0.515051</td>\n",
       "      <td>-0.410119</td>\n",
       "      <td>-1.214050</td>\n",
       "      <td>1.156639</td>\n",
       "      <td>1.048444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.347476</td>\n",
       "      <td>-0.921382</td>\n",
       "      <td>-0.710384</td>\n",
       "      <td>0.426308</td>\n",
       "      <td>1.108470</td>\n",
       "      <td>-0.648392</td>\n",
       "      <td>-0.410119</td>\n",
       "      <td>-1.214050</td>\n",
       "      <td>1.156639</td>\n",
       "      <td>-0.858012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 895 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Product_Info_4   Ins_Age        Ht        Wt       BMI  Employment_Info_1  \\\n",
       "0       -0.891949  1.803488  0.514174  0.003371 -0.277392          -0.393833   \n",
       "1       -0.891949 -0.467237 -0.955296 -1.288935 -1.111675          -0.454442   \n",
       "2        0.559979 -0.997073  0.514174  3.010921  3.273777          -0.212005   \n",
       "3       -0.347476  0.289671  0.024351 -1.288935 -1.592976          -0.515051   \n",
       "4       -0.347476 -0.921382 -0.710384  0.426308  1.108470          -0.648392   \n",
       "\n",
       "   Employment_Info_4  Employment_Info_6  Insurance_History_5  Family_Hist_2  \\\n",
       "0           2.559719          -0.405924             1.156639      -0.858012   \n",
       "1          -0.410119          -0.626160             1.156639       1.268046   \n",
       "2          -0.410119          -1.214050             1.156639       0.938644   \n",
       "3          -0.410119          -1.214050             1.156639       1.048444   \n",
       "4          -0.410119          -1.214050             1.156639      -0.858012   \n",
       "\n",
       "   ...  Medical_History_38_2  Medical_History_39_1  Medical_History_39_2  \\\n",
       "0  ...                   0.0                   0.0                   0.0   \n",
       "1  ...                   0.0                   0.0                   0.0   \n",
       "2  ...                   0.0                   0.0                   0.0   \n",
       "3  ...                   0.0                   0.0                   0.0   \n",
       "4  ...                   0.0                   0.0                   0.0   \n",
       "\n",
       "   Medical_History_39_3  Medical_History_40_1  Medical_History_40_2  \\\n",
       "0                   1.0                   0.0                   0.0   \n",
       "1                   1.0                   0.0                   0.0   \n",
       "2                   1.0                   0.0                   0.0   \n",
       "3                   1.0                   0.0                   0.0   \n",
       "4                   1.0                   0.0                   0.0   \n",
       "\n",
       "   Medical_History_40_3  Medical_History_41_1  Medical_History_41_2  \\\n",
       "0                   1.0                   0.0                   0.0   \n",
       "1                   1.0                   1.0                   0.0   \n",
       "2                   1.0                   1.0                   0.0   \n",
       "3                   1.0                   0.0                   0.0   \n",
       "4                   1.0                   1.0                   0.0   \n",
       "\n",
       "   Medical_History_41_3  \n",
       "0                   1.0  \n",
       "1                   0.0  \n",
       "2                   0.0  \n",
       "3                   1.0  \n",
       "4                   0.0  \n",
       "\n",
       "[5 rows x 895 columns]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "b7f1fb04",
   "metadata": {
    "id": "b7f1fb04",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setting up the parameter grid for hyperparameter tuning using GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "e04934e7",
   "metadata": {
    "id": "e04934e7"
   },
   "outputs": [],
   "source": [
    "# Initializing the RandomForestClassifier with a random state for reproducibility\n",
    "\n",
    "rf_classifier = RandomForestClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "a3278a78",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "a3278a78",
    "outputId": "dbfd1f68-bd61-4c9d-95d5-65ac6368810a",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=2, estimator=RandomForestClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [None, 10], &#x27;min_samples_leaf&#x27;: [1, 2],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=2, estimator=RandomForestClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [None, 10], &#x27;min_samples_leaf&#x27;: [1, 2],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=2, estimator=RandomForestClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={'max_depth': [None, 10], 'min_samples_leaf': [1, 2],\n",
       "                         'min_samples_split': [2, 5],\n",
       "                         'n_estimators': [100, 200]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Executing GridSearchCV to find the best hyperparameters based on the defined parameter grid and using cross-validation\n",
    "\n",
    "grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=2, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Note: Fork warnings are due to incompatibility between JAX's multithreading and joblib's multiprocessing. \n",
    "# This is just a warning and typically does not impact the execution of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "1bf8d013",
   "metadata": {
    "id": "1bf8d013"
   },
   "outputs": [],
   "source": [
    "# Extracting the best hyperparameters from the grid search\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Initializing RandomForestClassifier with the best parameters and fitting it to the training data\n",
    "\n",
    "best_rf_classifier = RandomForestClassifier(**best_params, random_state=42)\n",
    "best_rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the test set with the trained model\n",
    "\n",
    "test_predictions = best_rf_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "f490f35f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f490f35f",
    "outputId": "80313f13-87fb-4a21-a119-5ec0d245d5f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.5438278881778377\n",
      "Best Hyperparameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "# Retrieving the best score from the grid search and printing the best accuracy and hyperparameters\n",
    "\n",
    "best_accuracy = grid_search.best_score_\n",
    "print(\"Best Accuracy:\", best_accuracy)\n",
    "print(\"Best Hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "efc0f2a7",
   "metadata": {
    "id": "efc0f2a7"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "d352a547",
   "metadata": {
    "id": "d352a547"
   },
   "outputs": [],
   "source": [
    "# Defining the parameter grid for AdaBoostClassifier to be used in grid search\n",
    "# The grid specifies a range for 'n_estimators' and 'learning_rate' to find the best combination\n",
    "\n",
    "ada_param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'learning_rate': [0.1, 0.01]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "ab8e0a70",
   "metadata": {
    "id": "ab8e0a70"
   },
   "outputs": [],
   "source": [
    "# Initializing AdaBoostClassifier with a random state for reproducibility\n",
    "# The random state ensures the results are the same each time the classifier is run\n",
    "\n",
    "ada_classifier = AdaBoostClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "eae44b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_grid_search = GridSearchCV(estimator=ada_classifier, param_grid=ada_param_grid, cv=2, scoring='accuracy', n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "b73f5087",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 117
    },
    "id": "b73f5087",
    "outputId": "b64efbc2-b61f-4c2f-9fa7-7b2d769e817b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=2, estimator=AdaBoostClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.1, 0.01],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=2, estimator=AdaBoostClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.1, 0.01],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=2, estimator=AdaBoostClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.1, 0.01],\n",
       "                         'n_estimators': [50, 100]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performing GridSearchCV to tune AdaBoostClassifier with the defined parameter grid\n",
    "# This process will find the best hyperparameters based on cross-validation for the highest accuracyada_grid_search = GridSearchCV(estimator=ada_classifier, param_grid=ada_param_grid, cv=2, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "ada_grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "deaf6df8",
   "metadata": {
    "id": "deaf6df8"
   },
   "outputs": [],
   "source": [
    "# Retrieving the best hyperparameters for AdaBoost after GridSearchCV\n",
    "\n",
    "best_ada_params = ada_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "8428af2b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "8428af2b",
    "outputId": "5e766f9d-052b-4a09-c274-e91ea1b906ab"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostClassifier(learning_rate=0.1, n_estimators=100, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" checked><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier(learning_rate=0.1, n_estimators=100, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "AdaBoostClassifier(learning_rate=0.1, n_estimators=100, random_state=42)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the AdaBoost classifier with the best parameters obtained from the grid search\n",
    "\n",
    "best_ada_classifier = AdaBoostClassifier(**best_ada_params, random_state=42)\n",
    "best_ada_classifier.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c13949b9",
   "metadata": {
    "id": "c13949b9"
   },
   "outputs": [],
   "source": [
    "# Using the optimized AdaBoost classifier to make predictions on the test set\n",
    "\n",
    "ada_test_predictions = best_ada_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b48b525",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1b48b525",
    "outputId": "35e69001-a7a8-4e74-87fe-5edf78c916cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best AdaBoost Accuracy: 0.4873063320983496\n",
      "Best AdaBoost Hyperparameters: {'learning_rate': 0.1, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Displaying the best accuracy and hyperparameters for the AdaBoost model after grid search\n",
    "\n",
    "best_ada_accuracy = ada_grid_search.best_score_\n",
    "print(\"Best AdaBoost Accuracy:\", best_ada_accuracy)\n",
    "print(\"Best AdaBoost Hyperparameters:\", best_ada_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "2dd5dcee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2dd5dcee",
    "outputId": "e0df1d5d-9f73-46ee-9a81-5e703c5ac481",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy: 0.3922744974213241\n"
     ]
    }
   ],
   "source": [
    "# Loading the dataset from Google Drive and importing necessary functions for data preprocessing\n",
    "\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "# Separating features and target variable from the training data\n",
    "X = train_data.drop(columns=['Id','Response'])  # Separate features and target variable\n",
    "y = train_data['Response']\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Identifying numerical and categorical columns for imputation\n",
    "numeric_cols = X.select_dtypes(include=['float64', 'int64']).columns  # Separating numerical and categorical columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Imputing missing values in numerical columns with median and in categorical columns with the most frequent value\n",
    "imputer_numeric = SimpleImputer(strategy='median')  # Filling missing values with median for numerical columns and mode for categorical columns\n",
    "imputer_categorical = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# Applying the imputation to the train and test sets\n",
    "X_train[numeric_cols] = imputer_numeric.fit_transform(X_train[numeric_cols])\n",
    "X_train[categorical_cols] = imputer_categorical.fit_transform(X_train[categorical_cols])\n",
    "\n",
    "X_test[numeric_cols] = imputer_numeric.transform(X_test[numeric_cols])\n",
    "X_test[categorical_cols] = imputer_categorical.transform(X_test[categorical_cols])\n",
    "\n",
    "# Encoding categorical variables using label encoders\n",
    "label_encoders = {} \n",
    "for column in categorical_cols:\n",
    "    label_encoders[column] = LabelEncoder()\n",
    "    X_train[column] = label_encoders[column].fit_transform(X_train[column])\n",
    "    X_test[column] = label_encoders[column].transform(X_test[column])\n",
    "\n",
    "# Normalizing the features with StandardScaler to ensure that each feature contributes equally to the distance computation in KNN    \n",
    "scaler = StandardScaler() # Normalizing the features\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# K-Nearest Neighbors (KNN) Classifier\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_classifier.fit(X_train_scaled, y_train)\n",
    "knn_predictions = knn_classifier.predict(X_test_scaled)\n",
    "knn_accuracy = accuracy_score(y_test, knn_predictions)\n",
    "print(\"KNN Accuracy:\", knn_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "f38add31",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f38add31",
    "outputId": "91432351-f515-4833-e45a-72b88272f0f0",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.5044732133459636\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_classifier = LogisticRegression()\n",
    "logistic_classifier.fit(X_train_scaled, y_train)\n",
    "logistic_predictions = logistic_classifier.predict(X_test_scaled)\n",
    "logistic_accuracy = accuracy_score(y_test, logistic_predictions)\n",
    "print(\"Logistic Regression Accuracy:\", logistic_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ROr2Md78bUOV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ROr2Md78bUOV",
    "outputId": "8a80a1d2-1650-4951-bdda-d22d8df2a731"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shobhit/anaconda3/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 470us/step - accuracy: 0.4149 - loss: 1.5830 - val_accuracy: 0.5082 - val_loss: 1.3199\n",
      "Epoch 2/50\n",
      "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.5351 - loss: 1.2612 - val_accuracy: 0.5302 - val_loss: 1.2798\n",
      "Epoch 3/50\n",
      "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.5576 - loss: 1.2137 - val_accuracy: 0.5368 - val_loss: 1.2679\n",
      "Epoch 4/50\n",
      "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.5731 - loss: 1.1752 - val_accuracy: 0.5324 - val_loss: 1.2662\n",
      "Epoch 5/50\n",
      "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.5817 - loss: 1.1473 - val_accuracy: 0.5352 - val_loss: 1.2656\n",
      "Epoch 6/50\n",
      "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 416us/step - accuracy: 0.5837 - loss: 1.1456 - val_accuracy: 0.5363 - val_loss: 1.2717\n",
      "Epoch 7/50\n",
      "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - accuracy: 0.5947 - loss: 1.1130 - val_accuracy: 0.5347 - val_loss: 1.2763\n",
      "Epoch 8/50\n",
      "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - accuracy: 0.5983 - loss: 1.0988 - val_accuracy: 0.5359 - val_loss: 1.2858\n",
      "Epoch 9/50\n",
      "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - accuracy: 0.6094 - loss: 1.0851 - val_accuracy: 0.5334 - val_loss: 1.2974\n",
      "Epoch 10/50\n",
      "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - accuracy: 0.6122 - loss: 1.0768 - val_accuracy: 0.5343 - val_loss: 1.3025\n",
      "Epoch 11/50\n",
      "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.6167 - loss: 1.0672 - val_accuracy: 0.5333 - val_loss: 1.3105\n",
      "Epoch 12/50\n",
      "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412us/step - accuracy: 0.6221 - loss: 1.0529 - val_accuracy: 0.5326 - val_loss: 1.3196\n",
      "Epoch 13/50\n",
      "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407us/step - accuracy: 0.6248 - loss: 1.0428 - val_accuracy: 0.5345 - val_loss: 1.3204\n",
      "Epoch 14/50\n",
      "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.6311 - loss: 1.0348 - val_accuracy: 0.5280 - val_loss: 1.3504\n",
      "Epoch 15/50\n",
      "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - accuracy: 0.6308 - loss: 1.0290 - val_accuracy: 0.5271 - val_loss: 1.3485\n",
      "Epoch 16/50\n",
      "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412us/step - accuracy: 0.6358 - loss: 1.0194 - val_accuracy: 0.5268 - val_loss: 1.3685\n",
      "Epoch 17/50\n",
      "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - accuracy: 0.6359 - loss: 1.0151 - val_accuracy: 0.5250 - val_loss: 1.3673\n",
      "Epoch 18/50\n",
      "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - accuracy: 0.6419 - loss: 1.0064 - val_accuracy: 0.5214 - val_loss: 1.3763\n",
      "Epoch 19/50\n",
      "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - accuracy: 0.6420 - loss: 0.9990 - val_accuracy: 0.5237 - val_loss: 1.3870\n",
      "Epoch 20/50\n",
      "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413us/step - accuracy: 0.6496 - loss: 0.9769 - val_accuracy: 0.5174 - val_loss: 1.3968\n",
      "Epoch 21/50\n",
      "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407us/step - accuracy: 0.6522 - loss: 0.9757 - val_accuracy: 0.5247 - val_loss: 1.4026\n",
      "Epoch 22/50\n",
      "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - accuracy: 0.6537 - loss: 0.9707 - val_accuracy: 0.5219 - val_loss: 1.4086\n",
      "Epoch 23/50\n",
      "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 480us/step - accuracy: 0.6610 - loss: 0.9548 - val_accuracy: 0.5238 - val_loss: 1.4285\n",
      "Epoch 24/50\n",
      "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - accuracy: 0.6571 - loss: 0.9550 - val_accuracy: 0.5212 - val_loss: 1.4365\n",
      "Epoch 25/50\n",
      "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 467us/step - accuracy: 0.6630 - loss: 0.9388 - val_accuracy: 0.5192 - val_loss: 1.4418\n",
      "Epoch 26/50\n",
      "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407us/step - accuracy: 0.6575 - loss: 0.9520 - val_accuracy: 0.5159 - val_loss: 1.4609\n",
      "Epoch 27/50\n",
      "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 418us/step - accuracy: 0.6655 - loss: 0.9448 - val_accuracy: 0.5179 - val_loss: 1.4656\n",
      "Epoch 28/50\n",
      "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - accuracy: 0.6640 - loss: 0.9384 - val_accuracy: 0.5141 - val_loss: 1.4768\n",
      "Epoch 29/50\n",
      "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.6651 - loss: 0.9340 - val_accuracy: 0.5192 - val_loss: 1.4828\n",
      "Epoch 30/50\n",
      "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 451us/step - accuracy: 0.6675 - loss: 0.9274 - val_accuracy: 0.5148 - val_loss: 1.4925\n",
      "Epoch 31/50\n",
      "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 523us/step - accuracy: 0.6690 - loss: 0.9228 - val_accuracy: 0.5059 - val_loss: 1.5017\n",
      "Epoch 32/50\n",
      "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 423us/step - accuracy: 0.6696 - loss: 0.9185 - val_accuracy: 0.5176 - val_loss: 1.5268\n",
      "Epoch 33/50\n",
      "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412us/step - accuracy: 0.6667 - loss: 0.9264 - val_accuracy: 0.5117 - val_loss: 1.5237\n",
      "Epoch 34/50\n",
      "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 419us/step - accuracy: 0.6759 - loss: 0.9135 - val_accuracy: 0.5131 - val_loss: 1.5345\n",
      "Epoch 35/50\n",
      "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 587us/step - accuracy: 0.6694 - loss: 0.9097 - val_accuracy: 0.5145 - val_loss: 1.5296\n",
      "Epoch 36/50\n",
      "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 419us/step - accuracy: 0.6742 - loss: 0.9042 - val_accuracy: 0.5090 - val_loss: 1.5408\n",
      "Epoch 37/50\n",
      "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 415us/step - accuracy: 0.6729 - loss: 0.9106 - val_accuracy: 0.5088 - val_loss: 1.5604\n",
      "Epoch 38/50\n",
      "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 419us/step - accuracy: 0.6806 - loss: 0.8928 - val_accuracy: 0.5086 - val_loss: 1.5592\n",
      "Epoch 39/50\n",
      "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413us/step - accuracy: 0.6778 - loss: 0.8969 - val_accuracy: 0.5058 - val_loss: 1.5612\n",
      "Epoch 40/50\n",
      "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 422us/step - accuracy: 0.6824 - loss: 0.8882 - val_accuracy: 0.5063 - val_loss: 1.5654\n",
      "Epoch 41/50\n",
      "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - accuracy: 0.6781 - loss: 0.8948 - val_accuracy: 0.5052 - val_loss: 1.5785\n",
      "Epoch 42/50\n",
      "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 418us/step - accuracy: 0.6827 - loss: 0.8823 - val_accuracy: 0.5088 - val_loss: 1.5846\n",
      "Epoch 43/50\n",
      "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 418us/step - accuracy: 0.6855 - loss: 0.8765 - val_accuracy: 0.5047 - val_loss: 1.5926\n",
      "Epoch 44/50\n",
      "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 520us/step - accuracy: 0.6865 - loss: 0.8787 - val_accuracy: 0.5049 - val_loss: 1.5974\n",
      "Epoch 45/50\n",
      "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 418us/step - accuracy: 0.6885 - loss: 0.8741 - val_accuracy: 0.5038 - val_loss: 1.6025\n",
      "Epoch 46/50\n",
      "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412us/step - accuracy: 0.6880 - loss: 0.8727 - val_accuracy: 0.5024 - val_loss: 1.6225\n",
      "Epoch 47/50\n",
      "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 418us/step - accuracy: 0.6881 - loss: 0.8778 - val_accuracy: 0.5001 - val_loss: 1.6278\n",
      "Epoch 48/50\n",
      "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 422us/step - accuracy: 0.6857 - loss: 0.8720 - val_accuracy: 0.5054 - val_loss: 1.6315\n",
      "Epoch 49/50\n",
      "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - accuracy: 0.6850 - loss: 0.8789 - val_accuracy: 0.5002 - val_loss: 1.6376\n",
      "Epoch 50/50\n",
      "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412us/step - accuracy: 0.6905 - loss: 0.8631 - val_accuracy: 0.5014 - val_loss: 1.6351\n",
      "Test Loss: 1.637992262840271\n",
      "Test Accuracy: 0.5062726140022278\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261us/step\n",
      "Unique classes predicted: [1 2 3 4 5 6 7 8]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = train_data.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numerical_cols = train_data.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "numerical_cols.remove('Id')  # Removing 'Id' if it's part of numerical columns\n",
    "numerical_cols.remove('Response')  # Removing 'Response' as it's the target\n",
    "\n",
    "# Ensuring all categorical columns are type 'category' for correct processing\n",
    "train_data[categorical_cols] = train_data[categorical_cols].apply(lambda x: x.astype('category'))\n",
    "test_data[categorical_cols] = test_data[categorical_cols].apply(lambda x: x.astype('category'))\n",
    "\n",
    "# Setup the OneHotEncoder and StandardScaler\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Create the preprocessor with ColumnTransformer\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numerical_transformer, numerical_cols),\n",
    "    ('cat', categorical_transformer, categorical_cols)\n",
    "])\n",
    "\n",
    "# Preprocess data\n",
    "X_train = preprocessor.fit_transform(train_data.drop(['Id', 'Response'], axis=1))\n",
    "y_train = train_data['Response']\n",
    "X_test = preprocessor.transform(test_data.drop(['Id', 'Response'], axis=1))\n",
    "\n",
    "# Convert labels to categorical\n",
    "y_train_encoded = to_categorical(y_train)\n",
    "y_test_encoded = to_categorical(test_data['Response'])\n",
    "\n",
    "# Define the neural network model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_dim=X_train.shape[1]),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(y_train_encoded.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(X_train, y_train_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test_encoded, verbose=0)\n",
    "\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "# Check for unique predictions (debugging step)\n",
    "predictions = model.predict(X_test)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "unique_classes = np.unique(predicted_classes)\n",
    "print(f\"Unique classes predicted: {unique_classes}\")\n",
    "\n",
    "# Print early stopping if NaN loss is detected\n",
    "if np.isnan(history.history['loss']).any():\n",
    "    print(\"Training stopped due to NaN loss.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "487792b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243us/step\n"
     ]
    }
   ],
   "source": [
    "# Prediction Set for Neural Network\n",
    "predictions = model.predict(X_test)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "actual_classes = np.argmax(y_test_encoded, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "fWht9OZBjUBN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fWht9OZBjUBN",
    "outputId": "2ba757be-fe57-4ee5-b146-86ab8acec104"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def quadratic_weighted_kappa(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates the quadratic weighted kappa\n",
    "    kappa = 1 - (sum(w * O) / sum(w * E))\n",
    "    where O is the confusion matrix and E is the matrix of expected counts under independence.\n",
    "    \"\"\"\n",
    "    O = confusion_matrix(y_true, y_pred)\n",
    "    N = O.shape[0]\n",
    "    w = np.zeros((N, N))\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            w[i][j] = ((i - j) ** 2) / (N - 1) ** 2\n",
    "\n",
    "    # Compute the matrix of expected counts\n",
    "    E = np.outer(np.sum(O, axis=1), np.sum(O, axis=0)) / np.sum(O)\n",
    "\n",
    "    # Calculate kappa\n",
    "    kappa = 1 - (np.sum(w * O) / np.sum(w * E))\n",
    "    return kappa\n",
    "\n",
    "# Predict classes on the test set using the trained model\n",
    "#predictions = model.predict(X_test)\n",
    "#predicted_classes = np.argmax(predictions, axis=1)\n",
    "#actual_classes = np.argmax(y_test_encoded, axis=1)  # Make sure this matches the format of your actual test labels\n",
    "\n",
    "# Calculate the kappa score using the defined function for agreement between actual and predicted classes\n",
    "#kappa_score = quadratic_weighted_kappa(actual_classes, predicted_classes)\n",
    "#print(\"Quadratic Weighted Kappa:\", kappa_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab1add5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9rRIkx7cYdPX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9rRIkx7cYdPX",
    "outputId": "9ddbb30c-b792-4472-e95b-da034bd8ba83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Kappa: 0.38561988466173935\n"
     ]
    }
   ],
   "source": [
    "# Calculating the Kappa score for the K-Nearest Neighbors (KNN) model predictions\n",
    "knn_kappa = quadratic_weighted_kappa(y_test, nn_predictions)\n",
    "print(\"KNN Kappa:\", knn_kappa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "pO1C2SxFApdU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pO1C2SxFApdU",
    "outputId": "504143f3-4ccd-4e40-a54d-1cf940cc0de0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Kappa: 0.5290627898581586\n"
     ]
    }
   ],
   "source": [
    "# Generating predictions with the Random Forest model and calculating its Kappa score\n",
    "#rf_predictions = best_rf_classifier.predict(X_test)\n",
    "rf_kappa = quadratic_weighted_kappa(y_test, test_predictions)\n",
    "print(\"Random Forest Kappa:\", rf_kappa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "AY4v_dclc0pU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AY4v_dclc0pU",
    "outputId": "db306e99-fc7e-4b75-8a3a-d2af8283857b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Kappa: 0.5085070500173755\n"
     ]
    }
   ],
   "source": [
    "# Calculating the Kappa score for Logistic Regression model predictions\n",
    "logistic_kappa = quadratic_weighted_kappa(y_test, logistic_predictions)\n",
    "print(\"Logistic Regression Kappa:\", logistic_kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "qYOR4Xb9c-9Y",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qYOR4Xb9c-9Y",
    "outputId": "a40d6c01-d69b-4d49-a288-979066a43cb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Kappa: 0.4309616538345524\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Ensuring we are using the correct features in training\n",
    "\n",
    "ada_kappa=quadratic_weighted_kappa(y_test,ada_test_predictions)\n",
    "\n",
    "print(\"AdaBoost Kappa:\", ada_kappa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4441f608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetworkKappa: 0.5105409774280318\n"
     ]
    }
   ],
   "source": [
    "# Calculate the kappa score using the defined function for agreement between actual and predicted classes\n",
    "kappa_score = quadratic_weighted_kappa(actual_classes, predicted_classes)\n",
    "print(\"NeuralNetworkKappa:\", kappa_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a11b877",
   "metadata": {},
   "source": [
    "## Detailed Analysis\n",
    "\n",
    "#### Weak Models:\n",
    "\n",
    "##### KNN Model:\n",
    "\n",
    "###### Kappa Value: 0.3856\n",
    "\n",
    "###### Accuracy: 0.3923\n",
    "\n",
    "###### Reasons for Weakness:\n",
    "\n",
    ">KNN relies heavily on the local structure of the data and the choice of distance metric, which might not effectively capture complex relationships in the data.\n",
    "\n",
    ">It can be computationally expensive during inference, especially with large datasets.\n",
    "\n",
    "###### Impact on Performance:\n",
    "\n",
    ">With a Kappa value of 0.3856, the KNN model might struggle to generalize well to unseen data, especially in scenarios where the relationships between attributes and the target variable are complex or non-linear.\n",
    "\n",
    "##### AdaBoost Model:\n",
    "\n",
    "###### Kappa Value: 0.4309\n",
    "\n",
    "###### Accuracy: 0.4873\n",
    "\n",
    "###### Reasons for Weakness:\n",
    "\n",
    ">AdaBoost is sensitive to noisy data and outliers, which can lead to overfitting and suboptimal generalization.\n",
    "It may struggle to capture complex relationships in the data that cannot be represented by simple weak learners.\n",
    "\n",
    "###### Impact on Performance:\n",
    "\n",
    ">With a Kappa value of 0.4309, the AdaBoost model's performance might be limited by its sensitivity to noise and its inability to capture complex patterns effectively.\n",
    "\n",
    "#### Strong Models:\n",
    "\n",
    "##### Random Forest Model:\n",
    "\n",
    "###### Kappa Value: 0.5291\n",
    "\n",
    "###### Accuracy:  0.5464\n",
    "\n",
    "###### Reasons for Strength:\n",
    "\n",
    ">Random Forests are robust to overfitting and can handle complex relationships in the data effectively due to their ensemble nature.\n",
    "\n",
    ">They can capture non-linear interactions between features, making them suitable for a wide range of datasets.\n",
    "\n",
    "###### Impact on Performance:\n",
    "\n",
    ">With a Kappa value of 0.5291, the Random Forest model demonstrates strong performance in capturing complex patterns and relationships in the data.\n",
    "\n",
    "##### Neural Network Classifier:\n",
    "\n",
    "###### Kappa Value: 0.5105\n",
    "\n",
    "###### Accuracy Value: 00.5063\n",
    "\n",
    "\n",
    "###### Reasons for Strength:\n",
    "\n",
    ">Neural networks have the capacity to learn complex non-linear relationships in the data through multiple layers of neurons and activation functions.\n",
    "\n",
    ">They can automatically extract features from raw data, making them suitable for tasks with high-dimensional inputs or unstructured data.\n",
    "\n",
    "###### Impact on Performance:\n",
    "\n",
    ">With a Kappa value of 0.5105, the Neural Network Classifier excels in capturing intricate patterns and interactions among features, contributing to its strong performance.\n",
    "\n",
    "#### Medium Model:\n",
    "\n",
    "##### Logistic Regression Model:\n",
    "\n",
    "###### Kappa Value: 0.5085\n",
    "\n",
    "###### Accuracy: 0.5045\n",
    "\n",
    "###### Reasons for Medium Performance:\n",
    "\n",
    ">Logistic Regression assumes a linear relationship between the independent variables and the log-odds of the target variable, which might not capture the full complexity of the data.\n",
    "\n",
    ">It is less flexible compared to Random Forests and Neural Networks, especially in scenarios with non-linear relationships or interactions.\n",
    "\n",
    "###### Impact on Performance:\n",
    "\n",
    ">With a Kappa value of 0.5085, the Logistic Regression model demonstrates moderate performance, performing well when the relationship between predictors and the target is approximately linear. However, it may struggle in capturing non-linear relationships present in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63afa255",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
